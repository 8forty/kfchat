metadata:
  version: 2025-05-26.00:00:00PDT
  models_dir: /mnt/data/ggufs
  swap_dir: ./lswap

anchors:
  d0: &default-hc-timeout-secs 12000
  d1: &default-proxy http://localhost:27272

  c1: &cmd-default-server /home/kf/llamacpp/llama-b5558-bin-ubuntu-vulkan-x64/build/bin/llama-server
  c2: &cmd-default-extra --host 0.0.0.0 --port 27272
  c3: &cmd-ngl-999 -ngl 999
  c4: &cmd-ctx-2048 -c 2048
  v0:
    dev: &dev-vulkan0 -dev Vulkan0
  v1:
    dev: &dev-vulkan1 -dev Vulkan1
  v01:
    dev: &dev-vulkan01 -dev Vulkan0,Vulkan1
  cmd: &default-cmd
    server: *cmd-default-server
    ctx: *cmd-ctx-2048
    extra: *cmd-default-extra

all-yml:
  healthCheckTimeout: *default-hc-timeout-secs

all-gguf:
  defaults-cpu:
    proxy: *default-proxy
    cmd:
      <<: *default-cmd
  defaults-vulkan0-24gb:
    proxy: *default-proxy
    cmd:
      <<: *default-cmd
      dev: *dev-vulkan0
      ngl: *cmd-ngl-999
  defaults-vulkan0-24gb-fa:
    proxy: *default-proxy
    cmd:
      <<: *default-cmd
      dev: *dev-vulkan0
      ngl: *cmd-ngl-999
      extra: --port 27272 --flash-attn
  defaults-vulkan1-24gb:
    proxy: *default-proxy
    cmd:
      <<: *default-cmd
      dev: *dev-vulkan1
      ngl: *cmd-ngl-999
  defaults-vulkan1-24gb-fa:
    proxy: *default-proxy
    cmd:
      <<: *default-cmd
      dev: *dev-vulkan1
      ngl: *cmd-ngl-999
      extra: --port 27272 --flash-attn
  defaults-vulkan01:
    proxy: *default-proxy
    cmd:
      <<: *default-cmd
      dev: *dev-vulkan01
      ngl: *cmd-ngl-999
  defaults-vulkan01-fa:
    proxy: *default-proxy
    cmd:
      <<: *default-cmd
      dev: *dev-vulkan01
      ngl: *cmd-ngl-999
      extra: --port 27272 --flash-attn

custom-gguf:
  "phi-4-f16":
    swaps: [ 'defaults-vulkan0-24gb', 'defaults-vulkan0-24gb-fa', 'defaults-vulkan1-24gb', 'defaults-vulkan1-24gb-fa' ]
    cmd:
      ngl: -ngl 33
  "llama-3.3-70b-instruct-q4_k_m":
    swaps: [ 'defaults-vulkan0-24gb', 'defaults-vulkan0-24gb-fa', 'defaults-vulkan1-24gb', 'defaults-vulkan1-24gb-fa' ]
    cmd:
      ngl: -ngl 45
  "llama-3.3-70b-instruct-q8_0":
    swaps: [ 'defaults-vulkan0-24gb', 'defaults-vulkan0-24gb-fa', 'defaults-vulkan1-24gb', 'defaults-vulkan1-24gb-fa' ]
    cmd:
      ngl: -ngl 45
  "llama-3.3-70b-instruct":
    swaps: [ 'defaults-vulkan0-24gb', 'defaults-vulkan0-24gb-fa', 'defaults-vulkan1-24gb', 'defaults-vulkan1-24gb-fa' ]
    cmd:
      ngl: -ngl 45
